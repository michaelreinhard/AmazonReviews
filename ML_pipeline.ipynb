{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "\n",
    "#models\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import itertools as it \n",
    "\n",
    "nlp = spacy.load('en')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "def importdf_sample_magnitude(order_of_magnitude=None, random_state=None):\n",
    "    '''This function unpickle's the dataframe and returns a random sample of the DataFrame \n",
    "    of a specified magnitude. Allows user to specify the order of magnitude of a random \n",
    "    sampling of the DataFrame. The order_of_magnitude parameter defaults to None, in which \n",
    "    case the function returns the entire data frame. Otherwise, the user enters an integer \n",
    "    which determines the order of magnitude of the DataFrame. A random_state argument is\n",
    "    included as an option.\n",
    "    \n",
    "    IN: integer\n",
    "    OUT: DataFrame'''\n",
    "    df = pd.read_pickle('df_text.pk')\n",
    "    \n",
    "    if order_of_magnitude:\n",
    "        random_state = random_state\n",
    "        sample_size = 10**order_of_magnitude\n",
    "        df = df.sample(sample_size, random_state=random_state)\n",
    "        return df\n",
    "    else: \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#clean text\n",
    "def text_cleaner(df, variable='text_all', lemma_stopword=True, only_stopword=False):\n",
    "    '''\n",
    "    Takes in a dataframe as an argument and goes through spaCy procedures to \n",
    "    tokenize, lemmatize and remove stop_words. Returns a cleaned string for each \n",
    "    review in the data set.\n",
    "    '''\n",
    "    cleaned_text = []\n",
    "    \n",
    "    regex = re.compile(r'<span.*\\/span>|<br.\\/>|<\\/a >|<a href=.+?\\s>')\n",
    "    \n",
    "    \n",
    "    #takes avariable specified in arguments to iterate through\n",
    "    for text in df[variable]:\n",
    "        \n",
    "        text = str(text).lower() #just to make sure it is a string\n",
    "        \n",
    "        text = re.sub(regex,'',text)\n",
    "\n",
    "        text = nlp(text)\n",
    "        \n",
    "        if lemma_stopword==lemma_stopword:\n",
    "            cleaned = [token.lemma_ for token in text if token.is_punct==False and token.is_stop==False]\n",
    "            cleaned_text.append(' '.join(cleaned))\n",
    "        elif only_stopword==only_stopword:\n",
    "            cleaned = [token.text for token in text if token.is_punct==False and token.is_stop==False]\n",
    "            cleaned_text.append(' '.join(cleaned))\n",
    "        else: \n",
    "            cleaned_text = text\n",
    "    print(len(cleaned_text))\n",
    "    new_variable = f\"{variable}_cleaned\"\n",
    "    df[new_variable] = cleaned_text\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize text\n",
    "def std_scale(X_train, X_test):\n",
    "    '''Applies standard scaler to training and testing features of the data set.'''\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train)\n",
    "    X_train_std = ss.transform(X_train)\n",
    "    X_test_std = ss.transform(X_test)\n",
    "    return X_train_std, X_test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "#import 10k samples and lematize\n",
    "df = importdf_sample_magnitude(3,42)\n",
    "#clean the two text variables, text_all and Summary\n",
    "df_3 = text_cleaner(df, variable='text_all', lemma_stopword=True, only_stopword=False)\n",
    "df_3 = text_cleaner(df_3, variable='Summary', lemma_stopword=True, only_stopword=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = importdf_sample_magnitude(5,42)\n",
    "# #clean the two text variables, text_all and Summary\n",
    "# df_5_test = text_cleaner(df, variable='text_all', lemma_stopword=True, only_stopword=False)\n",
    "# df_5_test = text_cleaner(df_3, variable='Summary', lemma_stopword=True, only_stopword=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165256    crunchy good gluten free sandwich cookie have ...\n",
       "231465    great kitty treat cat love treat find house po...\n",
       "427827    coffee taste little expect   tend muddy taste ...\n",
       "433954    mini wheat big frost mini wheat original size ...\n",
       "70260     great taste want congratulate graphic artist p...\n",
       "Name: text_all_cleaned, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.text_all_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_3.text_all_cleaned.values\n",
    "y = df.positive.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Summary',\n",
       "       'text_all', 'positive', 'text_all_cleaned', 'Summary_cleaned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "95\n",
      "2\n",
      "56\n",
      "3\n",
      "69\n",
      "4\n",
      "151\n",
      "5\n",
      "629\n"
     ]
    }
   ],
   "source": [
    "for item in df_3.groupby('Score')['Score'].value_counts().items():\n",
    "    print(item[0][0])\n",
    "    print(item[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [(df.positive==0).sum(),(df.positive==1).sum()]\n",
    "x = ['0', '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB\n",
    "Ran the multinomialNB on count data. Does well. But I can standardize because it leads to negative values. I have not run the tfidf on this data yet because I have already determined that it does not work as well as the count data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        62\n",
      "           1       0.75      1.00      0.86       188\n",
      "\n",
      "    accuracy                           0.75       250\n",
      "   macro avg       0.38      0.50      0.43       250\n",
      "weighted avg       0.57      0.75      0.65       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "#get count data\n",
    "cnt_vctr = CountVectorizer()\n",
    "\n",
    "X_train_cnt = cnt_vctr.fit_transform(X_train)\n",
    "\n",
    "X_test_cnt = cnt_vctr.transform(X_test)\n",
    "\n",
    "# X_train_cnt_std, X_test_cnt_std = std_scale(X_train_cnt.todense(),X_test_cnt.todense())\n",
    "# can't standardize because centering on 0 causes negative values. Try Gaussian? \n",
    "\n",
    "#normalize (rather than standardize)\n",
    "\n",
    "nrmr = Normalizer() \n",
    "X_train_cnt_nrm = nrmr.transform(X_train_cnt)\n",
    "X_test_cnt_nrm = nrmr.transform(X_test_cnt)\n",
    "\n",
    "mulNB_cnt = MultinomialNB()\n",
    "mulNB_cnt.fit(X_train_cnt_nrm, y_train)\n",
    "\n",
    "results_s['multinomialNB_cnt']={}\n",
    "\n",
    "results_s['multinomialNB_cnt']['accuracy'] = accuracy_score(y_test, mulNB_cnt.predict(X_test_cnt_nrm))\n",
    "\n",
    "results_s['multinomialNB_cnt']['parameters']='defaults'\n",
    "\n",
    "\n",
    "\n",
    "results_s['multinomialNB_cnt']['report'] = classification_report(y_test, mulNB_cnt.predict(X_test_cnt_nrm))\n",
    "print(results_s['multinomialNB_cnt']['accuracy'])\n",
    "print(results_s['multinomialNB_cnt']['report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are supposed to see evidence that there is no gain in accuracy from standardization of the data. I'll go back and get this code running later if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# It is usually a good idea to scale the data for SVM training.\n",
    "# We are cheating a bit in this example in scaling all of the data,\n",
    "# instead of fitting the transformation on the training set and\n",
    "# just applying it on the test set.\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "#do svd on SVC\n",
    "svd = TruncatedSVD(n_components=100, n_iter=5, random_state=42)\n",
    "\n",
    "X_tfidf = svd.fit_transform(X_tfidf)\n",
    "# X_test_tfidf_svd = svd.transform(X_test_tfidf)\n",
    "\n",
    "C_range =  np.logspace(-2, 10, 13)\n",
    "gamma_range =  np.logspace(-9, 3, 13)\n",
    "kernel_types = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "param_grid = dict(kernel=kernel_types, gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_tfidf, y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_gridSearchSVC = grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8416666666666667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_gridSearchSVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8416666666666667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_3_tfidf_results_1000 = grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8416666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_3_tfidf_results_1000.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_ = \"The best parameters are {'C': 10000000.0, \\\n",
    "        'gamma': 9.9999999999999995e-08} with a score of 0.85\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score with 1000 dim: 0.8416666666666667\n",
      "Best score with 1000 dim, different kernels: 0.8416666666666667\n"
     ]
    }
   ],
   "source": [
    "# print(\"Best score with svd and 500 dim: {}\".format(SVC_3_tfidf_svd_results_500.best_score_))\n",
    "# print(\"Best score with svd and 800 dim: {}\".format(SVC_3_tfidf_svd_results.best_score_))\n",
    "# print(\"Best score with 500 dim: {}\".format(SVC_3_tfidf_results_500.best_score_))\n",
    "# print(\"Best score with 800 dim: {}\".format(SVC_3_tfidf_results.best_score_))\n",
    "print(\"Best score with 1000 dim: {}\".format(SVC_3_tfidf_results_1000.best_score_))\n",
    "print(\"Best score with 1000 dim, different kernels: {}\".format(full_gridSearchSVC.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000, 5525)\n"
     ]
    }
   ],
   "source": [
    "#full pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# It is usually a good idea to scale the data for SVM training.\n",
    "# We are cheating a bit in this example in scaling all of the data,\n",
    "# instead of fitting the transformation on the training set and\n",
    "# just applying it on the test set.\n",
    "print(X.shape)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do svd on SVC\n",
    "#I now know this is a stupidly high number of components for SVC \n",
    "svd = TruncatedSVD(n_components=1000, n_iter=5, random_state=42)\n",
    "\n",
    "X_tfidf = svd.fit_transform(X_tfidf)\n",
    "\n",
    "\n",
    "# X_test_tfidf_svd = svd.transform(X_test_tfidf)\n",
    "\n",
    "# C_range =  np.logspace(-2, 10, 13)\n",
    "# gamma_range =  np.logspace(-9, 3, 13)\n",
    "# #kernel_types = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"] --no effect, leave default at rbf\n",
    "# param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "# cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "# grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "# grid.fit(X_tfidf, y)\n",
    "\n",
    "# print(\"The best parameters are %s with a score of %0.2f\"\n",
    "#       % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n",
       "       1.e+06, 1.e+07, 1.e+08, 1.e+09, 1.e+10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-2, 10, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000000.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(1.00000000e+09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_3.text_all_cleaned.values\n",
    "y = df.positive.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'clf__C': 1, 'reduce_dim__n_components': 50, 'tfidf__max_df': 0.5, 'tfidf__min_df': 0.01} with a score of -0.39\n"
     ]
    }
   ],
   "source": [
    "'''this is close to the best model but I left the TruncatedSVD n_components really low and did \n",
    "not give the TruncatedSVD function a max number of features.''' \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "estimators = [('tfidf', TfidfVectorizer(ngram_range=(1, 2))), \n",
    "              ('reduce_dim', TruncatedSVD()), \n",
    "              ('clf', SVC(probability=True))]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = dict(tfidf__max_df=[0.25,0.05,0.1,0.2,0.5,0.8], \n",
    "                  tfidf__min_df=[0.01, 0.02], \n",
    "                  #tfidf__max_features=[10,50,100],\n",
    "                  #tfidf__ngram_range=(1,2),\n",
    "                  reduce_dim__n_components=[2,3,4,5,10,50],\n",
    "                  clf__C=[0.001, 1, 1000])\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=cv,scoring='neg_log_loss', n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 1, 'reduce_dim__n_components': 50, 'tfidf__max_df': 0.5, 'tfidf__min_df': 0.01}\n",
      "0.78\n",
      "-0.38891651002240574\n"
     ]
    }
   ],
   "source": [
    "predictions = grid.predict(X)\n",
    "print(grid.best_params_)\n",
    "print(accuracy_score(y, predictions))\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = importdf_sample_magnitude(5,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "df_5 = text_cleaner(df_5,'text_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = importdf_sample_magnitude(4,42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Summary',\n",
       "       'text_all', 'positive', 'text_all_cleaned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4 = text_cleaner(df_4, 'text_all')\n",
    "df_4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df_4.text_all_cleaned.values\n",
    "y= df_4.positive.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'tfidf__ngram_range': (1, 3), 'tfidf__max_features': 400, 'tfidf__max_df': 0.5, 'reduce_dim__n_components': 140, 'clf__gamma': 0.0001, 'clf__C': 1000} with a log loss of 0.37213881227951146\n"
     ]
    }
   ],
   "source": [
    "'''This is the one that finally worked. '''\n",
    "#this is a working model for testing theories\n",
    "# import timeit\n",
    "# %%timeit\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "X= df_4.text_all_cleaned.values\n",
    "y= df_4.positive.values\n",
    "\n",
    "\n",
    "\n",
    "estimators = [('tfidf', TfidfVectorizer()), \n",
    "              ('reduce_dim', TruncatedSVD()), \n",
    "              ('clf', SVC(probability=True))]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_distributions = dict(tfidf__max_df=[0.05, 0.1,0.2,0.5,0.8], \n",
    "                  #tfidf__min_df=[0.01, 0.02, 0.03 ], \n",
    "                  tfidf__max_features=[200,300,400], #Maybe do this with numbers over 100? \n",
    "                  tfidf__ngram_range=[(1,2),(1,3)],\n",
    "                  reduce_dim__n_components=[20,50,80,100,120,130,140,150],\n",
    "                  clf__C=[1, 100, 1000, 10000], \n",
    "                  clf__gamma=[0.1, 0.0001, 0.00001, 0.000001])\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "grid = RandomizedSearchCV(pipe, param_distributions=param_distributions, cv=cv, scoring='neg_log_loss',n_iter=25, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "predictions = grid.predict(X)\n",
    "\n",
    "print(\"The best parameters are {} with a log loss of {}\".format(grid.best_params_, -1*grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of the model is 0.8182\n"
     ]
    }
   ],
   "source": [
    "print('the accuracy of the model is {}'.format(accuracy_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.19      0.31      2148\n",
      "           1       0.82      0.99      0.90      7852\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.83      0.59      0.60     10000\n",
      "weighted avg       0.82      0.82      0.77     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.041 , 0.1738],\n",
       "       [0.008 , 0.7772]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y,predictions)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1]\n",
      "[1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y[:30])\n",
    "print(predictions[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.8182\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is {}\".format((TP + TN)/(TP + FP + TN + FN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity is 0.9898115129903209\n",
      "Sklearn's Sensitivity/Recall: 0.9898115129903209\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity is {}\".format(TP/(TP + FN)))\n",
    "print(\"Sklearn's Sensitivity/Recall: {}\".format(metrics.recall_score(y,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity is 0.1908752327746741\n",
      "No metric in Sklearn\n"
     ]
    }
   ],
   "source": [
    "print(\"Specificity is {}\".format(TN/(TN + FP)))\n",
    "print(\"No metric in Sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive 0.18275499474237644\n"
     ]
    }
   ],
   "source": [
    "print(\"False Positive {}\".format(FP/(TP + FP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score 0.8172450052576236\n",
      "Sklearn Precision Score: 0.8172450052576236\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision score {}\".format(TP/(TP+FP)))\n",
    "print(\"Sklearn Precision Score: {}\".format(metrics.precision_score(y,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a baseline for a dummy classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "X_dummy = np.array(np.linspace(0,100,10000))\n",
    "print(len(X_dummy))\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb = DummyClassifier( strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummy = X_dummy.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='most_frequent')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumb.fit(X_dummy,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dumb.predict(X_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.41910092315482"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.19087523 0.80912477]\n",
      " [0.01018849 0.98981151]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAEYCAYAAAAj5FFfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAV20lEQVR4nO3de5hdVX3G8e87A4EIgUcYLkISApqAkIcipBGJLVBBAyigIiFcWryExopVkSogjTG0VSlVAYMYvCGKgK3aiNGIPPIISjQRaEoCgRhEYoBcuAnkzq9/7H3syWFmzpnJmuw9Z78fnv149uWss8ZhXtZae619FBGYmbW7jqIrYGa2LTjszKwSHHZmVgkOOzOrBIedmVWCw87MKsFhVwGShkr6oaRnJX13K8o5S9JPU9atKJL+StKSouth2448z648JJ0JXAAcBPwJuA/414i4ayvLPQf4IHBURGza6oqWnKQARkfE0qLrYuXhll1JSLoA+ALwb8BewEjgGuCUBMXvBzxUhaBrhaTtiq6DFSAivBW8AbsCzwPv6uWaHcjCcEW+fQHYIT93DLAc+CiwEngceHd+7lPABmBj/hnvBaYD36orexQQwHb5/rnAMrLW5SPAWXXH76p731HAfODZ/H+Pqjt3B3AZ8Mu8nJ8CXT38bLX6f6yu/qcCJwIPAU8Bl9RdPx64G3gmv/aLwJD83C/yn+WF/OedVFf+x4EngBtqx/L3vDr/jMPz/X2A1cAxRf+74S3h31nRFfAWABOBTbWw6eGaGcA8YE9gD+BXwGX5uWPy988Ats9D4kXglfn5xnDrMeyAnYDngAPzc68CDslf/znsgN2Ap4Fz8vdNzvd3z8/fAfwOGAMMzfc/08PPVqv/tLz+U4BVwI3AMOAQYB1wQH79EcCR+eeOAh4APlxXXgCv6ab8z5L9R2Nofdjl10zJy3kFMBe4ouh/L7yl3dyNLYfdgdXRezfzLGBGRKyMiFVkLbZz6s5vzM9vjIg5ZK2aA/tZn5eAsZKGRsTjEbGom2tOAh6OiBsiYlNEfAd4EHhb3TVfj4iHImItcAtwWC+fuZFsfHIjcBPQBVwZEX/KP38RcChARPw2Iubln/t74MvA0S38TJ+MiPV5fbYQEdcBDwO/Jgv4TzQpzwYZh105rAG6mowl7QM8Wrf/aH7sz2U0hOWLwM59rUhEvEDW9ZsKPC7pR5IOaqE+tTrtW7f/RB/qsyYiNueva2H0ZN35tbX3Sxoj6VZJT0h6jmycs6uXsgFWRcS6JtdcB4wFro6I9U2utUHGYVcOd5N1007t5ZoVZDcaakbmx/rjBbLuWs3e9ScjYm5EHE/WwnmQLASa1adWpz/2s0598SWyeo2OiF2ASwA1eU+v0w4k7Uw2DvpVYLqk3VJU1MrDYVcCEfEs2XjVTEmnSnqFpO0lnSDp8vyy7wCXStpDUld+/bf6+ZH3AX8taaSkXYGLayck7SXpZEk7AevJusObuyljDjBG0pmStpM0CTgYuLWfdeqLYWTjis/nrc73N5x/Ejigj2VeCfw2It4H/Ai4dqtraaXisCuJiPgc2Ry7S8kG5x8Dzgd+kF/yL8ACYCHwv8A9+bH+fNZtwM15Wb9ly4DqILuru4LsDuXRwD90U8Ya4K35tWvI7qS+NSJW96dOfXQhcCbZXd7ryH6WetOB6yU9I+n0ZoVJOoXsJtHU/NAFwOGSzkpWYyucJxWbWSW4ZWdmleCwM7NKcNiZWSU47MysEhx2ZlYJpX/6wyt364p9ho8suhrWB0tWPFN0FayPNq95ZHVE7LE1ZXTusl/EppetxHuZWLtqbkRM3JrP6o/Sh90+w0dy05xfFF0N64Nj/3lbzCu2lNZ8Y3Lj0r8+i03r2OGgM5pet+7eq5st7RsQpQ87MxskBKjZqr3iOOzMLB2V9zaAw87M0nHLzszan6Cjs+hK9MhhZ2ZpCHdjzawK5G6smVWEW3ZmVglu2ZlZ+5NbdmZWAcJ3Y82sCtyyM7Oq6PCYnZm1O8+zM7PK8N1YM2t/Xi5mZlXhbqyZtT15uZiZVYVbdmZWCW7ZmVn786RiM6sCLxczs2pwy87MqsJjdmZWCW7ZmVkluGVnZm1PXi5mZhUht+zMrN0Jh52ZVYHyraQcdmaWiNyyM7NqcNiZWSV0dHienZm1O4/ZmVkVyGN2ZlYVDjszq4Qyh115RxPNbNCR1HRrsZyJkpZIWirpom7Oj5T0c0n3Sloo6cRmZTrszCwNgTrUdGtajNQJzAROAA4GJks6uOGyS4FbIuJ1wBnANc3KddiZWRK1GxQJWnbjgaURsSwiNgA3Aac0XBPALvnrXYEVzQr1mJ2ZJZNozG5f4LG6/eXA6xuumQ78VNIHgZ2A45oV6padmaWjFjbokrSgbjuvm1IaRcP+ZOAbETEcOBG4Qer9yaFu2ZlZGmq5Zbc6Isb1cn45MKJufzgv76a+F5gIEBF3S9oR6AJW9lSoW3ZmlkxHR0fTrQXzgdGS9pc0hOwGxOyGa/4AvAlA0muBHYFVvRXqlp2ZJZFqBUVEbJJ0PjAX6AS+FhGLJM0AFkTEbOCjwHWSPkLWxT03Ihq7ultw2JlZOonmFEfEHGBOw7Fpda8XAxP6UqbDzszSaH3MrhAOOzNLxmFnZpXgsDOzSmhlOVhRmt4HlrRZ0n1126herh0l6f6UFTSzwaGVpWJFtvxaadmtjYjDBrwmZjbolbkb269JxXkL7k5J9+TbUd1cc4ik3+StwYWSRufHz647/uX8CQdm1gbK3LJrJeyG1nVhv58fWwkcHxGHA5OAq7p531TgyrxVOA5Yns90ngRMyI9vBs5qfKOk82rr5p5+anU/fiwzK0Rra2ML0d9u7PbAFyXVAmtMN++7G/iEpOHA9yLiYUlvAo4A5ucJP5Ru1rJFxCxgFsAhhx7e66xoMyuPMndj+3s39iPAk8BfkLUO1zVeEBE3Svo1cBIwV9L7yHL9+oi4uJ+fa2YlJUHHYL4b24Ndgccj4iXgHLL1a1uQdACwLCKuIlvEeyhwO3CapD3za3aTtF8/62BmpVLuu7H9DbtrgL+TNI+sC/tCN9dMAu6XdB9wEPDNfD3bpWQP3VsI3Aa8qp91MLOSkZpvRWnajY2Inbs59jBZS63m4vz474Gx+etPA5/u5r03Azf3r7pmVmbtOGZnZralgltuzTjszCwJAZ2d5U07h52ZJeNurJm1P3djzawKhFt2ZlYJxc6ja8ZhZ2bJlDjrHHZmlkjJl4s57MwsCY/ZmVlllDjrHHZmlo5bdmZWCSXOOoedmSXiL8k2syoQ8t1YM6uGEjfsHHZmlo67sWbW/vwgADOrAk8qNrPK8A0KM6sEt+zMrP15zM7MqkB+np2ZVUWJs67fX5JtZvYyHVLTrRWSJkpaImmppIt6uOZ0SYslLZJ0Y7My3bIzsySU6OGdkjqBmcDxwHJgvqTZEbG47prRwMXAhIh4WtKezcp1y87MkulQ860F44GlEbEsIjYANwGnNFwzBZgZEU8DRMTKpnXr249iZtYzSU03oEvSgrrtvIZi9gUeq9tfnh+rNwYYI+mXkuZJmtisbu7GmlkyLQ7JrY6Icb0V082xaNjfDhgNHAMMB+6UNDYinumpULfszCwJkU8/afJPC5YDI+r2hwMrurnmvyNiY0Q8AiwhC78eOezMLA2Jzo7mWwvmA6Ml7S9pCHAGMLvhmh8Ax2Yfqy6ybu2y3gp12JlZMlLzrZmI2AScD8wFHgBuiYhFkmZIOjm/bC6wRtJi4OfAP0XEmt7K9ZidmSUhaHkeXTMRMQeY03BsWt3rAC7It5Y47MwsmTKvoHDYmVkyXhtrZm2v1TG5ojjszCyZzhKnncPOzJJxN9bM2l52N7boWvTMYWdmacgP7zSziihx1jnszCwdt+zMrO0JWl37WgiHnZklU96oc9iZWSJSurWxA8FhZ2bJlDjrHHZmlo5vUJhZ2xMtP5yzEA47M0vDDwLYOjtu38HovXcuuhrWBy/cd1fRVbCCuBtrZpVQ5u95cNiZWRLCLTszq4gS359w2JlZGpKXi5lZRZQ46xx2ZpZOiYfsHHZmlkbK740dCA47M0vGU0/MrBJK3LBz2JlZGpLXxppZRZQ46xx2ZpaGb1CYWWWUOOscdmaWiNyNNbMKENBZ4qadw87MknHLzswqwY94MrO2l92NLboWPSvz6g4zG0zy76BotrVUlDRR0hJJSyVd1Mt1p0kKSeOalemWnZklk2KenaROYCZwPLAcmC9pdkQsbrhuGPCPwK9bqttW18zMjPxubEfzrQXjgaURsSwiNgA3Aad0c91lwOXAulYKddiZWSKio4WtBfsCj9XtL8+P/f8nSa8DRkTEra3Wzt1YM0si+8Kdli7tkrSgbn9WRMxqKKpR/Pmk1AF8Hji3L/Vz2JlZGq2voFgdEb3dUFgOjKjbHw6sqNsfBowF7sinuuwNzJZ0ckTUh+gWHHZmlkyiBwHMB0ZL2h/4I3AGcGbtZEQ8C3TV9iXdAVzYW9CBx+zMLJFaN3Zrp55ExCbgfGAu8ABwS0QskjRD0sn9rZ9bdmaWTKqHd0bEHGBOw7FpPVx7TCtlOuzMLAlR7q6iw87M0pDXxppZRZQ36hx2ZpaIH8tuZpVR5qeeOOzMLBF5zM7M2p/vxppZZbhlZ2aVUN6oc9iZWSqeZ2dmVeCvUjSzyihv1DnszCyhEjfsHHZmlkY29aS8aeewM7Nk3LIzswoQcsvOzNqd78aaWTW0+Nj1ojjszCwZh52ZVYLH7Mys7WUP7yy6Fj1z2JlZMn5SsZlVQtt0YyXtDtye7+4NbAZW5fvjI2JDwrqZ2SDSVt3YiFgDHAYgaTrwfERcUX+Nsme8KCJeSlVJMxsMyj2pOMlTlCW9RtL9kq4F7gFGSHqm7vwZkr6Sv95L0vckLZD0G0lHpqiDmRUsn2fXbCtKyjG7g4F3R8RUSb2VexVweUTMkzQKuBUYm7AeZlaQ8rbr0obd7yJifgvXHQccWPdE01dKGhoRa2sHJJ0HnAcwYuTIhFU0s4FSpeViL9S9foktQ37Huteiyc2MiJgFzAI44ohxkbCOZjaQypt1A/PNZ/nNiacljZbUAby97vTPgA/UdiQdNhB1MLNtTy38U5SB/JrHjwM/IZuqsrzu+AeACZIWSloMTBnAOpjZNtSWNygiYnrd66XkU1Lqjt0M3NzN+1YBp/X3c82svErci/UKCjNLQ/irFM2sCvw8OzOrihJnncPOzBIqcdoN5N1YM6uUViaetJaGkiZKWiJpqaSLujl/gaTF+ayO2yXt16xMh52ZJZNi6omkTmAmcALZMtTJkg5uuOxeYFxEHAr8J3B5s3IddmaWRHY3Nsk8u/HA0ohYlq+0ugk4pf6CiPh5RLyY784Dhjcr1GFnZsm02I3typ96VNvOayhmX+Cxuv3l+bGevBf4cbO6+QaFmSXTYsttdUSM662Ybo51u0Ze0tnAOODoZh/qsDOzZBLdjF0OjKjbHw6seNlnSccBnwCOjoj1zQp1N9bM0lCLW3PzgdGS9pc0BDgDmL3FR0mvA74MnBwRK1sp1C07M0smxVNNImKTpPOBuUAn8LWIWCRpBrAgImYD/w7sDHw3X6L2h4g4ubdyHXZmlkTKL9yJiDnAnIZj0+peH9fXMh12ZpZOiVdQOOzMLJkyf7uYw87MkvFTT8ysEkqcdQ47M0vDD+80s2rwwzvNrCpKnHUOOzNLqMRp57Azs0SK/V7YZhx2ZpaMx+zMrO3VHt5ZVg47M0vG3VgzqwS37MysEkqcdQ47M0vEk4rNrDrKm3YOOzNLIuXDOweCw87MknE31swqwVNPzKwaypt1DjszS6fEWeewM7M0JOgo8aCdw87M0ilv1jnszCydEmedw87M0ilxL9ZhZ2ap+OGdZlYBfp6dmVWGw87MKsHdWDNrf37Ek5lVgfDUEzOrihKnncPOzJLxmJ2ZVYIf3mlm1eCwM7MqKHM3VhFRdB16JWkV8GjR9RggXcDqoithLWvn39d+EbHH1hQg6Sdk/x81szoiJm7NZ/VH6cOunUlaEBHjiq6Htca/r8Gto+gKmJltCw47M6sEh12xZhVdAesT/74GMY/ZmVkluGVnZpXgsDOzSnDYmVklOOzM+kDq/oltPR238vANipKQpPAvo9Tqf0eSpgBDgV0j4rJia2at8NrYEmj4IzoJCOBJ4B4HYHnU/Y6mAmcC7wcWSloVEdcWWjlryt3YEqj7I7oQuBCYAHwWOK7Ielmm1kWV1CFpKHAE8E7gaGAu8BVJQwqsorXAYVcSkvYDXh8RxwLrgXXA7ZJ2LLZmVte6HhYRa4GNwOeAY4F3RsQm4IOS3lpUHa05h11BuhnQXg9skHQdMJ7sj+gl4ERJ+2zzCtoWJI0HrpS0G3AXWTf24xGxVtIk4BxgcZF1tN55zK4ADWN0fws8ANxL9iirNwNnRsR6Se8BPgS8pbDKVlTtd9Rw4+gJYBpwMfAx4BZJS4D9gbMjYllB1bUW+G5sASR1RsRmSecDU4B3RMTvJE0ATiDrHs0HjgdOj4hFBVa30iS9ISLuzl8fDrwd2JVsbHUPYEdgbUSsKK6W1gqH3TYk6QjggYh4UdJBwPVkYfaopLeQtbTXkP0BvSK/9pHialxtknYHHgS+GREfzY8dCXwK+CMwPSL+UGAVrQ/cjd1G8jG6KcBYSW8GlgILgE/mw3f7kI3bfS8iri+sohUmaVRE/D5/PRXYCRgH/EzSxoi4KCLmSVoKbAI2FFdb6yvfoNhG8nGfD5ONzf0X2VeT3EI2qH1F/pjqecBfgmfkb2uSTgRukzRM0unAYcD3I+JR4BhgkqTPS/p74LXAZyPiieJqbH3lbuwAa1wZkc/HugbYi6wLuzY/fjbZONDkiHigkMpWVD6E8HngPXnL7UayOY4HRMTz+TV7A5eR/UfqqohYWFiFrV8cdgNIUkc+fQRJY4CNtTE4SV8BRgCnAnuS/SFdHhH3F1XfKsqHFG4A7gQuiYiHJO0CfJvs9/WOums7yP5mNhdTW9saDrttQNKHgNPIBrWfj4j35cevBcYCfwN01lp5tm1IehPwJbIbDnuT/Ufn1oi4Mw+8mcD2ZK1t/6EMch6zGwB5l6f2+izgXWTTSB4BzpX0Q4CImEo2hreXg64QzwHnRsS3gVvJbjicJGlCRDwHfIDszvjXC6yjJeKWXWL5Qv5PAidFxCpJ48hadO8gC7zTgGXA/0TE24qrqdXUhhskjSZbCTEEmB0Rv5I0jGyZmOfRDXJu2SUkaSJwETAtD7rtImIB8BRwJHB1vo7yBuBALwMrh9q4akQ8TPa7WQtMlvT6iPiTg649OOwSyddMzgH+IyJ+IunVwFfzialBttToSEmXAKOAN/qPqHzywLsZWEE27GBtwmGXSEQ8BbwNmCbpULKv3bs3ItZExAbgtvzSNwKfiYiVBVXVmoiIB8nmPvp31EY8ZpdY3pWdQzaN4TN5V3ZT3fntI2JjcTU0qyaH3QCQdDxwNdnz6Z6VNCRv3ZlZQRx2A0TSCcAXgDfkXVwzK5AfBDBAIuLH+dKwn+XTT8ITU82K45bdAJO0c219pZkVx2FnZpXgqSdmVgkOOzOrBIedmVWCw87MKsFhZ2aV4LAzs0r4P65GZHCWJ29aAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#classes correspond to 0,1\n",
    "classes = ['False','True']\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    \n",
    "    \n",
    "plot_confusion_matrix(confusion,classes, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(grid.predict_proba(X));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = grid.predict_proba(X)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilties = [p[1] for p in predicted_probabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(probabilties);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "s = pickle.dumps(grid)\n",
    "new_grid = pickle.loads(s)\n",
    "new_grid.predict([\"I hate this product and everyone that eats this crap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../flask_app_test/grid.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-5e181f530397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../flask_app_test/grid.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../flask_app_test/grid.pkl'"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(grid, '../flask_app_test/grid.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other things to try:\n",
    "\n",
    ">The latent dirichlet idea for engineering features\n",
    ">More features like the helpfulness rating of the review writer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "#run with 100000 cases Monday night. \n",
    "df_5 = text_cleaner(df_5, 'text_all')\n",
    "X= df_5.text_all_cleaned.values\n",
    "y= df_5.positive.values\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "estimators = [('tfidf', TfidfVectorizer()), \n",
    "              ('reduce_dim', TruncatedSVD()), \n",
    "              ('clf', SVC(probability=True))]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_distributions = dict(tfidf__max_df=[0.1,0.2,0.5,0.8], \n",
    "                  #tfidf__min_df=[0.01, 0.02, 0.03 ], \n",
    "                  #tfidf__max_features=[10,50,100], Maybe do this with numbers over 100? \n",
    "                  tfidf__ngram_range=[(1,2),(1,3)],\n",
    "                  reduce_dim__n_components=[2,5,10,20,50],\n",
    "                  clf__C=[0.001, 1, 1000, 10000], \n",
    "                  clf__gamma=[0.1, 0.0001])\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "grid = RandomizedSearchCV(pipe, param_distributions=param_distributions, cv=cv, scoring='neg_log_loss', n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "predictions = grid.predict(X)\n",
    "\n",
    "print(\"The best parameters are {} with a log loss of {}\".format(grid.best_params_, -1*grid.best_score_))\n",
    "print('the accuracy of the model with 10^5 is {}'.format(accuracy_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Model = grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some last minute attempts. First, lay out the baseline MNB, LR, and SVM models.\n",
    "\n",
    "Add new model: Random Forest? That is a last priority.\n",
    "\n",
    "First, run the final version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Best Model tested on Larger Data Set, n = 100000\n",
    "DATA PREP:\n",
    "    TfidfVectorizer: ngram_range=(1,3); max_df=0.5\n",
    "    TruncatedSVD: n_components=20\n",
    "MODEL: \n",
    "    gamma=0.0001\n",
    "    C=1000\n",
    "RESULTS:\n",
    "    log loss: 0.4301\n",
    "    Accuracy: 0.7826\n",
    "The best parameters are {'tfidf__ngram_range': (1, 3), 'tfidf__max_df': 0.5,\n",
    "'reduce_dim__n_components': 20, 'clf__gamma': 0.0001, 'clf__C': 1000} with \n",
    "a log loss of 0.4301149914560899; the accuracy of the model \n",
    "with 10^5 is 0.78263.'''\n",
    "\n",
    "\n",
    "### run the final form of the model\n",
    "# X = df_3.text_all.values\n",
    "# y = df_3.positive.values\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y)\n",
    "\n",
    "# tfidf_vec = TfidfVectorizer(ngram_range=(1,3), max_df=0.5)\n",
    "# X_train_tfidf = tfidf_vec.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf_vec.transform(X_test)\n",
    "\n",
    "# svd = TruncatedSVD(n_components=20)\n",
    "# X_train_tfidf_svd =svd.fit_transform(X_train_tfidf)\n",
    "# X_test_tfidf_svd =svd.fit_transform(X_test_tfidf)\n",
    "\n",
    "\n",
    "# svc = SVC(probability=True, C=1000,gamma=0.0001)\n",
    "# svc.fit(X_train_tfidf_svd,y_train)\n",
    "# predictions = svc.predict(X_test_tfidf_svd)\n",
    "# accuracy_score(y_test, predictions)\n",
    "\n",
    "#run on all data for the app\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,3), max_df=0.5)\n",
    "X_t = tfidf_vec.fit_transform(X)\n",
    "\n",
    "svd = TruncatedSVD(n_components=20)\n",
    "X_t_s = svd.fit_transform(X_t)\n",
    "print(X_t_s.shape)\n",
    "\n",
    "print(type(X_t_s))\n",
    "# np.save()\n",
    "\n",
    "### Grid Search for final model\n",
    "# estimators = [('tfidf', TfidfVectorizer()), \n",
    "#               ('reduce_dim', TruncatedSVD()), \n",
    "#               ('clf', SVC(probability=True))]\n",
    "# pipe = Pipeline(estimators)\n",
    "\n",
    "# param_distributions = dict(tfidf__max_df=[0.1,0.2,0.5,0.8], \n",
    "#                   #tfidf__min_df=[0.01, 0.02, 0.03 ], \n",
    "#                   #tfidf__max_features=[10,50,100], Maybe do this with numbers over 100? \n",
    "#                   tfidf__ngram_range=[(1,2),(1,3)],\n",
    "#                   reduce_dim__n_components=[2,5,10,20,50],\n",
    "#                   clf__C=[0.001, 1, 1000, 10000], \n",
    "#                   clf__gamma=[0.1, 0.0001])\n",
    "\n",
    "# cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "# grid = RandomizedSearchCV(pipe, param_distributions=param_distributions, cv=cv, scoring='neg_log_loss', n_jobs=-1)\n",
    "# grid.fit(X, y)\n",
    "# predictions = grid.predict(X)\n",
    "\n",
    "# print(\"The best parameters are {} with a log loss of {}\".format(grid.best_params_, -1*grid.best_score_))\n",
    "# print('the accuracy of the model with 10^5 is {}'.format(accuracy_score(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'tfidf__ngram_range': (1, 2), 'tfidf__max_features': 400, 'tfidf__max_df': 0.5, 'reduce_dim__n_components': 150, 'clf__gamma': 1e-06, 'clf__C': 100} with a log loss of 0.3818472562554885\n"
     ]
    }
   ],
   "source": [
    "#this is a working model for testing theories\n",
    "# import timeit\n",
    "# %%timeit\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "X= df_3.text_all_cleaned.values\n",
    "y= df_3.positive.values\n",
    "\n",
    "\n",
    "\n",
    "estimators = [('tfidf', TfidfVectorizer()), \n",
    "              ('reduce_dim', TruncatedSVD()), \n",
    "              ('clf', SVC(probability=True))]\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_distributions = dict(tfidf__max_df=[0.05, 0.1,0.2,0.5,0.8], \n",
    "#                   tfidf__min_df=[0.01, 0.02, 0.03 ], \n",
    "                  tfidf__max_features=[200,300,400], #Maybe do this with numbers over 100? \n",
    "                  tfidf__ngram_range=[(1,2),(1,3)],\n",
    "                  reduce_dim__n_components=[20,50,80,100,120,130,140,150],\n",
    "                  clf__C=[1, 100, 1000, 10000], \n",
    "                  clf__gamma=[0.1, 0.0001, 0.00001, 0.000001])\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "grid = RandomizedSearchCV(pipe, param_distributions=param_distributions, cv=cv, scoring='neg_log_loss',n_iter=25, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "predictions = grid.predict(X)\n",
    "\n",
    "print(\"The best parameters are {} with a log loss of {}\".format(grid.best_params_, -1*grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "['Crunchy Good Gluten Free Sandwich Cookies have try couple brand gluten free sandwich cookie good bunch   crunchy true texture real cookie gluten free   think filling make bit sweet mean satisfy sweet tooth sooner   chocolate version Glutino good true chocolatey taste gluten free brand'\n",
      " 'great kitty treat cat love treat find house pop bolt hide come treat like crunchy treat perfect give flavor like equally tend dry time near end bottle flip lid handy nice inexpensive kitty treat meet cat love'\n",
      " 'COFFEE taste little expect   tend muddy taste expect say favorite company'\n",
      " 'Mini Wheats big frost Mini Wheats original size frost Mini Wheats Bite Size reason mouthful frost Mini wheat Little Bits yes half size Bite Size version particular Cinnamon roll\".there new table exception size unnecessary personally like original flavor size good Bite Size edition accommodate come desperate attempt attention brand need sort life come make small have new flavor actually sweet serve size approximately 47 biscuit s 1 gram polyunsaturate fat 46 gram carbohydrate 6 g fiber 12 g sugar 5 g protein 200 mg potassium generally look good guess watch carb intake want careful probably fit spoon better predecessor bowl milk like kind cause snack better milk small one easily snack grade product 2 star 3 reason 1 not think make small reason exist outside Kellogs fill shelf version fine begin 2 flavor Cinnamon Roll sweet synthetic taste 3 plus like Mini Wheats general save star'\n",
      " 'Great Taste want congratulate graphic artist put entire product small box   ad man think long hard seriously love product taste refresh think taste pleasing aftertaste   sweet Goldilocks stop right choice 3   Easy use pour content 16 oz bottle water shake   Mixed granulation ask Lipton like good drug dealer know taste free life   5 star'\n",
      " 'Lifesavers Pineapple flavor add Pineapple flavor package lifesaver fact sell pineapple flavor'\n",
      " 'good Tea absolutely love Yorkshire tea glad available Amazon   cup bodied black tea milk morning start day love'\n",
      " 'Lady Grey hit hard time find loose tea locally able order favorite Lady Grey tea Amazon convenient timesaving tea come pack tin right size insure continue freshness speedy shipping'\n",
      " 'pretty good rice noodle previously attempt recipe white rice noodle overcook soggy determine overcook brown rice noodle try make dish miso soup brown rice noodle broth miso green onion noodle add hot noodle soften puff think soften water maybe rinse broth end little starchy noodle pretty good noodle flavor flavor dish rice noodle miso probably good idea mild miso flavor noodle flavor try stir fry noodle well soak noodle hot water minute drain come clear kind crunchy stir fry garlic onion salt coconut oil add vinegar nama shoyu flavor noodle come crunchy spicy actually pretty good nice thing noodle need minute warm water fry add soup dish fairly versatile gluten free brown rice noodle firm white rice noodle reviewer post look like noodle Singapore'\n",
      " 'simply good pancake waffle Saturday morning kid simply comparison product baking powder come expensive brand Trader Joe Foods pale comparison Batter come light fluffy time kid love know eat pancake pack 6 store']\n",
      "165256    Crunchy & Good Gluten-Free Sandwich Cookies! ....\n",
      "231465    great kitty treats . My cat loves these treats...\n",
      "427827    COFFEE TASTE . A little less than I expected. ...\n",
      "433954    So the Mini-Wheats were too big? . First there...\n",
      "70260     Great Taste . . . . and I want to congratulate...\n",
      "49866     Lifesavers - Pineapple flavor . Please add mor...\n",
      "551047    The Best Tea! . I absolutely love Yorkshire te...\n",
      "18983     Lady Grey a hit! . I have such a hard time fin...\n",
      "138968    Pretty good rice noodles . Previously, I've at...\n",
      "36352     Simply the best . I make pancakes or waffles e...\n",
      "Name: text_all, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#this is a working model for testing theories\n",
    "# import timeit\n",
    "# %%timeit\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# df_4 = importdf_sample_magnitude(4,42)\n",
    "df_3 = importdf_sample_magnitude(3, 42)\n",
    "\n",
    "\n",
    "df_3 = text_cleaner(df_3, 'text_all')\n",
    "\n",
    "print(df_3.text_all_cleaned.values[:10])\n",
    "print(df_3.text_all[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'tfidf__ngram_range': (1, 2), 'tfidf__max_features': 400, 'tfidf__max_df': 0.5, 'reduce_dim__n_components': 150, 'clf__gamma': 1e-06, 'clf__C': 100} with a log loss of 0.3818472562554885\n"
     ]
    }
   ],
   "source": [
    "X = df_3.text_all_cleaned.values\n",
    "y = df_3.positive.values\n",
    "\n",
    "\n",
    "\n",
    "estimators = [('tfidf', TfidfVectorizer(max_df=0.5, max_features=400, ngram_range=(1,3))), \n",
    "              ('reduce_dim', TruncatedSVD(n_components=150)), \n",
    "              ('clf', SVC(probability=True, C=100, gamma=0.000001))]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "\n",
    "# cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "# grid = RandomizedSearchCV(pipe, param_distributions=param_distributions, cv=cv, scoring='neg_log_loss',n_iter=25, n_jobs=-1)\n",
    "\n",
    "\n",
    "pipe.fit(X, y)\n",
    "predictions = pipe.predict(X)\n",
    "\n",
    "print(f\"The best parameters are {grid.best_params_} with a log loss of {-1*grid.best_score_}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_case_pred = pipe.predict(['crunchy good gluten free sandwich cookie have try couple brand gluten free sandwich cookie good bunch   crunchy true texture real cookie gluten free   think filling make bit sweet mean satisfy sweet tooth sooner   chocolate version glutino good true chocolatey taste gluten free brand'])\n",
    "one_case_pred[0]            \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.22],\n",
       "       [0.  , 0.78]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y, predictions)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'tfidf', TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
